{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "a0bf0fa7-c527-4fd3-b504-02a88fc94798",
    "_uuid": "1382c63fe24710d3b2840e7dcf172cddbf533743",
    "colab": {},
    "colab_type": "code",
    "id": "JleJ3lvzGip6"
   },
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8603,
     "status": "ok",
     "timestamp": 1600488718998,
     "user": {
      "displayName": "Hariom Pandya",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg8d7lqNqBxgfXVdhraKxXVYdefhGJQ6fR34vxZkw=s64",
      "userId": "14308869011554137018"
     },
     "user_tz": -330
    },
    "id": "sO1OgzmSO0cN",
    "outputId": "814d9643-a4a0-470a-b6b4-4511981f80ca"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "\n",
    "(features_train, targets_train), (features_test, targets_test) = mnist.load_data()\n",
    "\n",
    "# Convert to float32.\n",
    "\n",
    "features_train, features_test = np.array(features_train, np.float32), np.array(features_test, np.float32)\n",
    "\n",
    "# Flatten images to 1-D vector of 784 features (28*28).\n",
    "num_features=784\n",
    "\n",
    "features_train, features_test = features_train.reshape([-1, num_features]), features_test.reshape([-1, num_features])\n",
    "\n",
    "# Normalize images value from [0, 255] to [0, 1].\n",
    "\n",
    "features_train, features_test = features_train / 255., features_test / 255\n",
    "\n",
    "# create feature and targets tensor for train set. As you remember we need variable to accumulate gradients. \n",
    "#Therefore first we create tensor, then we will create variable\n",
    "featuresTrain = torch.from_numpy(features_train)\n",
    "targetsTrain = torch.from_numpy(targets_train).type(torch.LongTensor) # data type is long\n",
    "\n",
    "# create feature and targets tensor for test set.\n",
    "featuresTest = torch.from_numpy(features_test)\n",
    "targetsTest = torch.from_numpy(targets_test).type(torch.LongTensor) # data type is long\n",
    "\n",
    "# batch_size, epoch and iteration\n",
    "batch_size = 100\n",
    "n_iters = 5000\n",
    "num_epochs = n_iters / (len(features_train) / batch_size)\n",
    "num_epochs = int(num_epochs)\n",
    "\n",
    "# Pytorch train and test sets\n",
    "train = torch.utils.data.TensorDataset(featuresTrain,targetsTrain)\n",
    "test = torch.utils.data.TensorDataset(featuresTest,targetsTest)\n",
    "\n",
    "# data loader\n",
    "train_loader = DataLoader(train, batch_size = batch_size, shuffle = False)\n",
    "test_loader = DataLoader(test, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "# visualize one of the images in data set\n",
    "plt.imshow(featuresTrain[10].reshape(28,28))\n",
    "plt.axis(\"off\")\n",
    "plt.title(str(targetsTrain[10]))\n",
    "plt.savefig('graph.png')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "3472f1c1-5888-4abe-822c-3a493a5f8be5",
    "_uuid": "cefd0bb2f23b80f30ca65cbb08859ad81ab12e08",
    "colab": {},
    "colab_type": "code",
    "id": "wy2W0meBGis6"
   },
   "outputs": [],
   "source": [
    "# Create ANN Model\n",
    "class ANNModel(nn.Module):\n",
    "    \n",
    "  def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "    super(ANNModel, self).__init__()\n",
    "    self.layer1 = nn.Linear(input_dim, hidden_dim)\n",
    "    self.layer2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "    self.layer3 = nn.Linear(hidden_dim, output_dim)\n",
    "    self.relu = nn.ReLU()\n",
    "  \n",
    "  def forward(self, x):\n",
    "    return self.layer3(self.relu(self.layer2(self.relu(self.layer1(x)))))\n",
    "\n",
    "# instantiate ANN\n",
    "input_dim = 28*28\n",
    "hidden_dim = 150 #hidden layer dim is one of the hyper parameter and it should be chosen and tuned. For now I only say 150 there is no reason.\n",
    "output_dim = 10\n",
    "\n",
    "# Create ANN\n",
    "model = ANNModel(input_dim, hidden_dim, output_dim)\n",
    "\n",
    "# Cross Entropy Loss \n",
    "error = nn.CrossEntropyLoss()\n",
    "\n",
    "# SGD Optimizer\n",
    "learning_rate = 0.02\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "7550e98b-5011-4d09-88ee-97b0ecbc6f19",
    "_uuid": "c91694f3af94e4e1b76ab01489e186718c70ccd3",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 40843,
     "status": "ok",
     "timestamp": 1600488751269,
     "user": {
      "displayName": "Hariom Pandya",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg8d7lqNqBxgfXVdhraKxXVYdefhGJQ6fR34vxZkw=s64",
      "userId": "14308869011554137018"
     },
     "user_tz": -330
    },
    "id": "-nFSRfE4GitJ",
    "outputId": "5c9d2d5d-036c-4162-ffb5-03524ab6098f"
   },
   "outputs": [],
   "source": [
    "# ANN model training\n",
    "count = 0\n",
    "loss_list = []\n",
    "iteration_list = []\n",
    "accuracy_list = []\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "\n",
    "        train = Variable(images.view(-1, 28*28))\n",
    "        labels = Variable(labels)\n",
    "        \n",
    "        # Clear gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward propagation\n",
    "        outputs = model(train)\n",
    "        \n",
    "        # Calculate softmax and ross entropy loss\n",
    "        loss = error(outputs, labels)\n",
    "        \n",
    "        # Calculating gradients\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        count += 1\n",
    "        \n",
    "        if count % 50 == 0:\n",
    "            # Calculate Accuracy         \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            # Predict test dataset\n",
    "            for images, labels in test_loader:\n",
    "\n",
    "                test = Variable(images.view(-1, 28*28))\n",
    "                \n",
    "                # Forward propagation\n",
    "                outputs = model(test)\n",
    "                \n",
    "                # Get predictions from the maximum value\n",
    "                predicted = torch.max(outputs.data, 1)[1]\n",
    "                \n",
    "                # Total number of labels\n",
    "                total += len(labels)\n",
    "\n",
    "                # Total correct predictions\n",
    "                correct += (predicted == labels).sum()\n",
    "            \n",
    "            accuracy = 100 * correct / float(total)\n",
    "            \n",
    "            # store loss and iteration\n",
    "            loss_list.append(loss.data)\n",
    "            iteration_list.append(count)\n",
    "            accuracy_list.append(accuracy)\n",
    "        if count % 500 == 0:\n",
    "            # Print Loss\n",
    "            print('Iteration: {}  Loss: {}  Accuracy: {} %'.format(count, loss.data, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "5579a7d6-7766-4d0f-b9d0-584cb4f28321",
    "_uuid": "c5e2e6da7f1ee801e38358dc28d4c99e32d2b761",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 40833,
     "status": "ok",
     "timestamp": 1600488751279,
     "user": {
      "displayName": "Hariom Pandya",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg8d7lqNqBxgfXVdhraKxXVYdefhGJQ6fR34vxZkw=s64",
      "userId": "14308869011554137018"
     },
     "user_tz": -330
    },
    "id": "WhnlGGNNGitc",
    "outputId": "1ca21136-e1a2-4f50-a2cb-8c2590acbc4d"
   },
   "outputs": [],
   "source": [
    "# visualization loss \n",
    "plt.plot(iteration_list,loss_list)\n",
    "plt.xlabel(\"Number of iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"ANN: Loss vs Number of iteration\")\n",
    "plt.show()\n",
    "\n",
    "# visualization accuracy \n",
    "plt.plot(iteration_list,accuracy_list,color = \"red\")\n",
    "plt.xlabel(\"Number of iteration\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"ANN: Accuracy vs Number of iteration\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xSPdXTvy9QHL"
   },
   "outputs": [],
   "source": [
    "# Create CNN Model\n",
    "class CNNModel(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(CNNModel, self).__init__()\n",
    "\n",
    "    ######################################################################       \n",
    "    #### DESIGN LAYERS :\n",
    "    ### SEQUENCE: CONV1,ACTIVATION1,POOLING1,  CONV2,ACTIVATION2,POOLING2, LINEAR(FC)\n",
    "    self.layer1 = nn.Conv2d(1, 2, 5)\n",
    "    self.relu = nn.ReLU()\n",
    "    self.pool1 = nn.MaxPool2d(2)\n",
    "    self.layer2 = nn.Conv2d(2, 4, 5)\n",
    "    self.pool2 = nn.MaxPool2d(4)\n",
    "    self.layer3 = nn.Linear(4 * 2 * 2, 10)\n",
    "\n",
    "  def forward(self, x):\n",
    "    # COMBINE LAYERS\n",
    "    ## 1) CONV1\n",
    "    out = self.layer1(x)\n",
    "\n",
    "    ## 2) ACTIVATION1\n",
    "    out = self.relu(out)\n",
    "\n",
    "    ## 3) POOLING1\n",
    "    out = self.pool1(out)\n",
    "    \n",
    "    ## 4) CONV2\n",
    "    out = self.layer2(out)\n",
    "\n",
    "    ## 5) ACTIVATION2\n",
    "    out = self.relu(out)\n",
    "\n",
    "    ## 6) POOLING2\n",
    "    out = self.pool2(out)\n",
    "\n",
    "    ## 7) flatten ########## DURING LAB WE JUST FORGOT FOLLOWING FLATTEN LAYER ###############\n",
    "    out = out.view(out.size(0), -1)\n",
    "\n",
    "    ## 8) LINEAR(FC)\n",
    "    return self.layer3(out)\n",
    "\n",
    "\n",
    "# batch_size, epoch and iteration\n",
    "batch_size = 100\n",
    "n_iters = 2500\n",
    "num_epochs = n_iters / (len(features_train) / batch_size)\n",
    "num_epochs = int(num_epochs)\n",
    "\n",
    "# Pytorch train and test sets\n",
    "train = torch.utils.data.TensorDataset(featuresTrain,targetsTrain)\n",
    "test = torch.utils.data.TensorDataset(featuresTest,targetsTest)\n",
    "\n",
    "# data loader\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size = batch_size, shuffle = False)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size = batch_size, shuffle = False)\n",
    "    \n",
    "# Create CNN\n",
    "model = CNNModel()\n",
    "\n",
    "# Cross Entropy Loss \n",
    "error = nn.CrossEntropyLoss()\n",
    "\n",
    "# SGD Optimizer\n",
    "learning_rate = 0.1\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 193289,
     "status": "ok",
     "timestamp": 1600488903759,
     "user": {
      "displayName": "Hariom Pandya",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg8d7lqNqBxgfXVdhraKxXVYdefhGJQ6fR34vxZkw=s64",
      "userId": "14308869011554137018"
     },
     "user_tz": -330
    },
    "id": "FHHjyUcC9TRa",
    "outputId": "67cde587-4881-4663-92c8-171ad395290b"
   },
   "outputs": [],
   "source": [
    "# CNN model training\n",
    "count = 0\n",
    "loss_list = []\n",
    "iteration_list = []\n",
    "accuracy_list = []\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        \n",
    "        train = Variable(images.view(100,1,28,28))\n",
    "        labels = Variable(labels)\n",
    "        \n",
    "        # Clear gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward propagation\n",
    "        outputs = model(train)\n",
    "        \n",
    "        # Calculate softmax and ross entropy loss\n",
    "        loss = error(outputs, labels)\n",
    "        \n",
    "        # Calculating gradients\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        count += 1\n",
    "        \n",
    "        if count % 50 == 0:\n",
    "            # Calculate Accuracy         \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            # Iterate through test dataset\n",
    "            for images, labels in test_loader:\n",
    "                \n",
    "                test = Variable(images.view(100,1,28,28))\n",
    "                \n",
    "                # Forward propagation\n",
    "                outputs = model(test)\n",
    "                \n",
    "                # Get predictions from the maximum value\n",
    "                predicted = torch.max(outputs.data, 1)[1]\n",
    "                \n",
    "                # Total number of labels\n",
    "                total += len(labels)\n",
    "                \n",
    "                correct += (predicted == labels).sum()\n",
    "            \n",
    "            accuracy = 100 * correct / float(total)\n",
    "            \n",
    "            # store loss and iteration\n",
    "            loss_list.append(loss.data)\n",
    "            iteration_list.append(count)\n",
    "            accuracy_list.append(accuracy)\n",
    "        if count % 500 == 0:\n",
    "            # Print Loss\n",
    "            print('Iteration: {}  Loss: {}  Accuracy: {} %'.format(count, loss.data, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 193292,
     "status": "ok",
     "timestamp": 1600488903777,
     "user": {
      "displayName": "Hariom Pandya",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg8d7lqNqBxgfXVdhraKxXVYdefhGJQ6fR34vxZkw=s64",
      "userId": "14308869011554137018"
     },
     "user_tz": -330
    },
    "id": "JI7FgspY9WnN",
    "outputId": "41d7d986-e054-4fcb-954b-508ec220de63"
   },
   "outputs": [],
   "source": [
    "# visualization loss \n",
    "plt.plot(iteration_list,loss_list)\n",
    "plt.xlabel(\"Number of iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"CNN: Loss vs Number of iteration\")\n",
    "plt.show()\n",
    "\n",
    "# visualization accuracy \n",
    "plt.plot(iteration_list,accuracy_list,color = \"red\")\n",
    "plt.xlabel(\"Number of iteration\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"CNN: Accuracy vs Number of iteration\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tCuk3R3y5kx9"
   },
   "source": [
    "Try CNN on \"Fruit\" dataset. Also modify number of layers and observe the performance difference: \n",
    "\n",
    "https://www.kaggle.com/moltean/fruits\n",
    "\n",
    "\n",
    "Or (In a case if you don't have that much dataPack available, download 20 images of apple and 20 images of orange from the internet and work on it with RANDOM state=Rollnumber stratergy, 80-20% training-testing division)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "ANN_CNN-UPDATED.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "6cd9a464138fc6ccabc335c6117ac38c085d16cbe40298286e63ec121b3c4a6a"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
